{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gpt-2-simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.download_gpt2(model_name=\"774M\")\n",
    "gpt2.download_gpt2(model_name=\"355M\")\n",
    "gpt2.download_gpt2(model_name=\"1558M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
    "\n",
    "!unzip python.zip\n",
    "\n",
    "!gzip -d python/final/jsonl/train/python_train_0.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_1.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_2.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_3.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_4.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_5.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_6.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_7.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_8.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_9.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_10.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_11.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_12.jsonl.gz\n",
    "!gzip -d python/final/jsonl/train/python_train_13.jsonl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_sets = []\n",
    "include = 14\n",
    "for i in range(include):\n",
    "  print(i)\n",
    "  fname = f\"python/final/jsonl/train/python_train_{str(i)}.jsonl\"\n",
    "  cur = pd.read_json(fname, lines=True)\n",
    "  cur2 = cur[\"code\"]\n",
    "  all_sets.append(cur2)\n",
    "set1 = pd.concat(all_sets, axis=0)\n",
    "\n",
    "set1 = set1.to_frame()\n",
    "\n",
    "set1[\"length\"] = set1[\"code\"].str.len()\n",
    "set1 = set1[ set1[\"length\"] < 1000]\n",
    "\n",
    "\n",
    "def find_real_funcs(row):\n",
    "  word_list = row[\"code\"].split()\n",
    "  if len(word_list) < 3 or len(word_list[1]) < 2:\n",
    "    return False\n",
    "  else:\n",
    "    if word_list[1][0] == \"_\":\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "\n",
    "set1[\"internal_func\"] = set1.apply(find_real_funcs, axis=1)\n",
    "set1 = set1[ set1[\"internal_func\"]]\n",
    "\n",
    "def find_return_funcs(row):\n",
    "  sent_list = row[\"code\"].split(\"\\n\")\n",
    "  if len(sent_list[-1]) == 0:\n",
    "    return False\n",
    "  else:\n",
    "    if \"return\" in sent_list[-1]:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "set1[\"has_return\"] = set1.apply(find_return_funcs, axis=1)\n",
    "set1 = set1[ set1[\"has_return\"]]\n",
    "set1 = set1.reset_index(drop=True)\n",
    "\n",
    "def put_return_first(row):\n",
    "  code = row[\"code\"].split(\"\\n\")\n",
    "  return_line = code[-1]\n",
    "  code = code[:-1]\n",
    "  code.insert(1, return_line)\n",
    "  code = \"\\n\".join(code)\n",
    "  return code\n",
    "\n",
    "set1[\"updated_code\"] = set1.apply( put_return_first, axis=1)\n",
    "set1 = set1[\"updated_code\"]\n",
    "full_frame = set1\n",
    "full_frame = full_frame.astype(str) + \"\\n <|endoftext|> \" \n",
    "\n",
    "full_frame.to_csv(\"python/final/jsonl/train/gptready.txt\", index=False, header=False, sep=\"\\n\")\n",
    "full_frame.head()\n",
    "full_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"python/final/jsonl/train/gptready.txt\"\n",
    "full_frame = None\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "# 774M\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='355M',\n",
    "              steps=-1,\n",
    "              restore_from='fresh',\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              sample_every=200,\n",
    "              save_every=500\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate(sess,\n",
    "              run_name = \"run1\",\n",
    "              prefix=\"def join_text(text_list):\\n    return joined_text\",\n",
    "              nsamples=20,\n",
    "              batch_size=5,\n",
    "              top_p = 0.9,\n",
    "              temperature = 0.8\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
